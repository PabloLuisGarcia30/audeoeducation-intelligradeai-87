export interface BatchJob {
  id: string;
  files: File[];
  status: 'pending' | 'processing' | 'completed' | 'failed' | 'paused';
  priority: 'low' | 'normal' | 'high';
  createdAt: number;
  startedAt?: number;
  completedAt?: number;
  progress: number;
  results: any[];
  errors: string[];
  estimatedTimeRemaining?: number;
  atomicProcessing?: boolean; // Flag to indicate atomic processing is enabled
}

export interface QueueStatus {
  activeJobs: BatchJob[];
  pendingJobs: BatchJob[];
  completedJobs: BatchJob[];
}

export class BatchProcessingService {
  private static readonly QUEUE_MANAGER_URL = 'https://irnkilorodqvhizmujtq.supabase.co/functions/v1/batch-queue-manager';
  private static queue: QueueStatus = {
    activeJobs: [],
    pendingJobs: [],
    completedJobs: []
  };
  private static jobListeners: Map<string, (job: BatchJob) => void> = new Map();

  static async createBatchJob(files: File[], priority: 'low' | 'normal' | 'high' = 'normal'): Promise<string> {
    try {
      // Convert files to a serializable format
      const fileData = await Promise.all(
        files.map(async (file) => ({
          name: file.name,
          size: file.size,
          type: file.type,
          fileContent: await this.fileToBase64(file)
        }))
      );

      console.log(`ðŸŽ¯ Creating batch job with atomic processing: ${files.length} files, priority: ${priority}`);

      const response = await fetch(`${this.QUEUE_MANAGER_URL}/submit`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImlybmtpbG9yb2Rxdmhpem11anRxIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDkwMjM2OTUsImV4cCI6MjA2NDU5OTY5NX0.9wRY7Qj1NTEWukOF902PhpPoR_iASywfAqkTQP6ySOw`
        },
        body: JSON.stringify({
          files: fileData,
          priority,
          maxRetries: 3
        })
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Failed to create batch job: ${response.status} - ${errorText}`);
      }

      const result = await response.json();
      console.log(`âœ… Batch job created successfully:`, result);

      // Create local representation
      const localJob: BatchJob = {
        id: result.jobId,
        files,
        status: 'pending',
        priority,
        createdAt: Date.now(),
        progress: 0,
        results: [],
        errors: [],
        atomicProcessing: true
      };

      this.queue.pendingJobs.push(localJob);
      this.saveQueueState();

      // Start polling for updates
      this.pollJobStatus(result.jobId);

      return result.jobId;
    } catch (error) {
      console.error('Failed to create batch job:', error);
      throw error;
    }
  }

  private static async pollJobStatus(jobId: string) {
    const pollInterval = 2000; // Poll every 2 seconds
    const maxPollTime = 30 * 60 * 1000; // Stop polling after 30 minutes
    const startTime = Date.now();

    const poll = async () => {
      try {
        if (Date.now() - startTime > maxPollTime) {
          console.log(`Stopped polling job ${jobId} after 30 minutes`);
          return;
        }

        const response = await fetch(`${this.QUEUE_MANAGER_URL}/status?jobId=${jobId}`, {
          headers: {
            'Authorization': `Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImlybmtpbG9yb2Rxdmhpem11anRxIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDkwMjM2OTUsImV4cCI6MjA2NDU5OTY5NX0.9wRY7Qj1NTEWukOF902PhpPoR_iASywfAqkTQP6ySOw`
          }
        });

        if (!response.ok) {
          console.error(`Failed to check job status: ${response.status}`);
          return;
        }

        const jobStatus = await response.json();
        this.updateLocalJobStatus(jobStatus);

        // Continue polling if job is still active
        if (jobStatus.status === 'pending' || jobStatus.status === 'processing') {
          setTimeout(poll, pollInterval);
        }
      } catch (error) {
        console.error('Error polling job status:', error);
        setTimeout(poll, pollInterval * 2); // Retry with longer interval
      }
    };

    poll();
  }

  private static updateLocalJobStatus(remoteJob: any) {
    const allJobs = [
      ...this.queue.pendingJobs,
      ...this.queue.activeJobs,
      ...this.queue.completedJobs
    ];

    const localJobIndex = allJobs.findIndex(job => job.id === remoteJob.id);
    if (localJobIndex === -1) return;

    const localJob = allJobs[localJobIndex];
    
    // Update local job with remote status
    const updatedJob: BatchJob = {
      ...localJob,
      status: remoteJob.status,
      progress: remoteJob.progress || 0,
      results: remoteJob.results || [],
      errors: remoteJob.errors || [],
      startedAt: remoteJob.started_at ? new Date(remoteJob.started_at).getTime() : localJob.startedAt,
      completedAt: remoteJob.completed_at ? new Date(remoteJob.completed_at).getTime() : localJob.completedAt,
      atomicProcessing: true
    };

    // Move job to appropriate queue
    this.removeJobFromAllQueues(remoteJob.id);
    
    switch (remoteJob.status) {
      case 'pending':
        this.queue.pendingJobs.push(updatedJob);
        break;
      case 'processing':
        this.queue.activeJobs.push(updatedJob);
        break;
      case 'completed':
      case 'failed':
        this.queue.completedJobs.unshift(updatedJob);
        // Keep only last 50 completed jobs
        if (this.queue.completedJobs.length > 50) {
          this.queue.completedJobs = this.queue.completedJobs.slice(0, 50);
        }
        break;
    }

    this.saveQueueState();
    this.notifyJobUpdate(updatedJob);
  }

  private static removeJobFromAllQueues(jobId: string) {
    this.queue.pendingJobs = this.queue.pendingJobs.filter(job => job.id !== jobId);
    this.queue.activeJobs = this.queue.activeJobs.filter(job => job.id !== jobId);
    this.queue.completedJobs = this.queue.completedJobs.filter(job => job.id !== jobId);
  }

  static async triggerProcessing(): Promise<void> {
    try {
      console.log('ðŸš€ Triggering atomic batch processing');
      
      const response = await fetch(`${this.QUEUE_MANAGER_URL}/process-next`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImlybmtpbG9yb2Rxdmhpem11anRxIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDkwMjM2OTUsImV4cCI6MjA2NDU5OTY5NX0.9wRY7Qj1NTEWukOF902PhpPoR_iASywfAqkTQP6ySOw`
        }
      });

      if (!response.ok) {
        console.error(`Failed to trigger processing: ${response.status}`);
      } else {
        console.log('âœ… Atomic processing triggered successfully');
      }
    } catch (error) {
      console.error('Error triggering processing:', error);
    }
  }

  static async getQueueStats(): Promise<any> {
    try {
      const response = await fetch(`${this.QUEUE_MANAGER_URL}/queue-stats`, {
        headers: {
          'Authorization': `Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6ImlybmtpbG9yb2Rxdmhpem11anRxIiwicm9sZSI6ImFub24iLCJpYXQiOjE3NDkwMjM2OTUsImV4cCI6MjA2NDU5OTY5NX0.9wRY7Qj1NTEWukOF902PhpPoR_iASywfAqkTQP6ySOw`
        }
      });

      if (!response.ok) {
        throw new Error(`Failed to get queue stats: ${response.status}`);
      }

      return await response.json();
    } catch (error) {
      console.error('Error getting queue stats:', error);
      return null;
    }
  }

  static getQueueStatus(): QueueStatus {
    return { ...this.queue };
  }

  static subscribeToJob(jobId: string, callback: (job: BatchJob) => void): void {
    this.jobListeners.set(jobId, callback);
  }

  static unsubscribeFromJob(jobId: string): void {
    this.jobListeners.delete(jobId);
  }

  private static notifyJobUpdate(job: BatchJob): void {
    const listener = this.jobListeners.get(job.id);
    if (listener) {
      listener({ ...job });
    }
  }

  static pauseJob(jobId: string): boolean {
    // Note: Pausing remote jobs is not implemented in the queue manager yet
    // This would require API endpoint updates
    console.log(`Pause functionality not yet implemented for remote job: ${jobId}`);
    return false;
  }

  static resumeJob(jobId: string): boolean {
    // Note: Resuming remote jobs is not implemented in the queue manager yet
    // This would require API endpoint updates
    console.log(`Resume functionality not yet implemented for remote job: ${jobId}`);
    return false;
  }

  private static saveQueueState(): void {
    try {
      localStorage.setItem('batchProcessingQueue', JSON.stringify(this.queue));
    } catch (error) {
      console.warn('Failed to save queue state:', error);
    }
  }

  static loadQueueState(): void {
    try {
      const saved = localStorage.getItem('batchProcessingQueue');
      if (saved) {
        const savedQueue = JSON.parse(saved);
        
        // Filter out any jobs that might be stale (older than 1 hour)
        const oneHourAgo = Date.now() - 60 * 60 * 1000;
        
        this.queue = {
          pendingJobs: savedQueue.pendingJobs?.filter((job: BatchJob) => job.createdAt > oneHourAgo) || [],
          activeJobs: savedQueue.activeJobs?.filter((job: BatchJob) => job.createdAt > oneHourAgo) || [],
          completedJobs: savedQueue.completedJobs?.filter((job: BatchJob) => job.completedAt && job.completedAt > oneHourAgo) || []
        };
      }
    } catch (error) {
      console.warn('Failed to load queue state:', error);
    }
  }

  private static async fileToBase64(file: File): Promise<string> {
    return new Promise((resolve, reject) => {
      const reader = new FileReader();
      reader.readAsDataURL(file);
      reader.onload = () => {
        if (typeof reader.result === 'string') {
          // Remove the data:mime;base64, prefix
          const base64 = reader.result.split(',')[1];
          resolve(base64);
        } else {
          reject(new Error('Failed to convert file to base64'));
        }
      };
      reader.onerror = reject;
    });
  }
}
